{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "thrown-welsh",
   "metadata": {},
   "source": [
    "Safety can be roughly translated as the agent avoiding bad trajectories (state/action).\n",
    "\n",
    "We aim at improving the policy, so that the output of the safety function, i.e. how quantifiably safe\n",
    "is my current state and action pair, is as small as possible.\n",
    "\n",
    "**Approach and artefacts**\n",
    "\n",
    "A seperate **Safety Controller** is used to advice the agent in critical states with action probabilities to ensure risk minimization. While the agent generally aims at accumelating the biggest expected return over a set of trajectories, the seperate Safety Controller network is aimed at minimizing risk. In the provided environment (LunarSafe-v0) we are given the values of risk measured by safety bounds, i.e. the vector between the coordinates of the Lander and predetermined boundaries. The Controller thereby modifies the optimizaiton criterion toward which the policy tends to converge, and the exploration process for the agent to include the notation of safety. \n",
    "\n",
    "\n",
    "The main function of the Safety Controller is to learn which states are unsafe, and which actions to take in proximity to those states. It learns the unsafe state in through a constraint given by the environment. It "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fourth-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import safe_agents as sa\n",
    "import matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-tissue",
   "metadata": {},
   "source": [
    "## Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-algeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0  | score: 14.896757222653946  | memory: 70 | epsilon: 0.9930240953515695\n",
      "episode: 1  | score: -249.00764300545558  | memory: 157 | epsilon: 0.9844218297185002\n",
      "episode: 2  | score: -151.40998432918562  | memory: 291 | epsilon: 0.9713179143142632\n",
      "episode: 3  | score: -54.63902572726187  | memory: 425 | epsilon: 0.9583884288075943\n",
      "episode: 4  | score: -5.047438606285652  | memory: 512 | epsilon: 0.9500862014166829\n",
      "episode: 5  | score: -105.39856779714327  | memory: 628 | epsilon: 0.9391283320998\n",
      "episode: 6  | score: -183.52558318048125  | memory: 731 | epsilon: 0.9295044770190672\n",
      "episode: 7  | score: -102.9616415783691  | memory: 834 | epsilon: 0.9199792438023008\n",
      "episode: 8  | score: -83.82657573479983  | memory: 914 | epsilon: 0.9126484057557739\n",
      "episode: 9  | score: -260.8099151144768  | memory: 1030 | epsilon: 0.9021223272298245\n",
      "episode: 10  | score: -206.82854610278423  | memory: 1097 | epsilon: 0.8960980104149296\n",
      "episode: 11  | score: -46.70527590464661  | memory: 1223 | epsilon: 0.884877452416852\n",
      "episode: 12  | score: -36.1217485672357  | memory: 1322 | epsilon: 0.8761599525834685\n",
      "episode: 13  | score: -10.758390397789896  | memory: 1414 | epsilon: 0.8681358472915321\n",
      "episode: 14  | score: -19.586493360754787  | memory: 1489 | epsilon: 0.8616488606911034\n",
      "episode: 15  | score: -334.1306354362035  | memory: 1596 | epsilon: 0.8524779114079739\n",
      "episode: 16  | score: -97.8711757998297  | memory: 1705 | epsilon: 0.8432359005326565\n",
      "episode: 17  | score: -22.671578448873902  | memory: 1791 | epsilon: 0.8360148059422513\n",
      "episode: 18  | score: -130.17537314629914  | memory: 1857 | epsilon: 0.8305150025447616\n",
      "episode: 19  | score: -33.32307265361851  | memory: 1985 | epsilon: 0.8199516321375078\n",
      "episode: 20  | score: 14.371368421169976  | memory: 2097 | epsilon: 0.8108189556758053\n",
      "episode: 21  | score: -116.7394389705305  | memory: 2222 | epsilon: 0.8007463003450978\n",
      "episode: 22  | score: -4.267377225273947  | memory: 2313 | epsilon: 0.7934922025079341\n",
      "episode: 23  | score: 21.24979800354882  | memory: 2400 | epsilon: 0.7866184209595359\n",
      "episode: 24  | score: 42.38854825398529  | memory: 2550 | epsilon: 0.7749066171800192\n",
      "episode: 25  | score: -80.42963723717642  | memory: 2687 | epsilon: 0.7643622630541387\n",
      "episode: 26  | score: -147.50578601031572  | memory: 2787 | epsilon: 0.7567563530573902\n",
      "episode: 27  | score: -145.37179040868415  | memory: 2880 | epsilon: 0.7497507950300561\n",
      "episode: 28  | score: -147.0416532806292  | memory: 3088 | epsilon: 0.7343162821780369\n",
      "episode: 29  | score: 54.591178016872256  | memory: 3221 | epsilon: 0.724614053352899\n",
      "episode: 30  | score: 21.72360977783609  | memory: 3349 | epsilon: 0.7153976435054971\n",
      "episode: 31  | score: -82.3900586949359  | memory: 3497 | epsilon: 0.7048872019775732\n",
      "episode: 32  | score: -213.75020814180652  | memory: 3617 | epsilon: 0.6964786871172362\n",
      "episode: 33  | score: -84.75938132771887  | memory: 3719 | epsilon: 0.689410360835819\n",
      "episode: 34  | score: 30.379099509541746  | memory: 3885 | epsilon: 0.6780600495573512\n",
      "episode: 35  | score: -60.94686115884235  | memory: 3994 | epsilon: 0.6707089636602663\n",
      "episode: 36  | score: 54.18425113916467  | memory: 4147 | epsilon: 0.660524715472386\n",
      "episode: 37  | score: 117.83191483893053  | memory: 4251 | epsilon: 0.6536905161541529\n",
      "episode: 38  | score: -74.5871659308365  | memory: 4377 | epsilon: 0.6455052816551893\n",
      "episode: 39  | score: -55.40163336738786  | memory: 4472 | epsilon: 0.6394017141478041\n",
      "episode: 40  | score: 77.80554581795849  | memory: 4628 | epsilon: 0.6295039557621022\n",
      "episode: 41  | score: -89.6182470110756  | memory: 4775 | epsilon: 0.620317474352276\n",
      "episode: 42  | score: -11.355079428570093  | memory: 4943 | epsilon: 0.6099826793978044\n",
      "episode: 43  | score: 1.7458960909189187  | memory: 5040 | epsilon: 0.6040941584763089\n",
      "episode: 44  | score: 62.387054642767964  | memory: 5353 | epsilon: 0.5854779441385861\n",
      "episode: 45  | score: -99.87594257336096  | memory: 5547 | epsilon: 0.5742285811982462\n",
      "episode: 46  | score: 5.761333554473566  | memory: 5699 | epsilon: 0.5655658769673878\n",
      "episode: 47  | score: -10.504771277124775  | memory: 5830 | epsilon: 0.5582049154953953\n",
      "episode: 48  | score: -13.97392693545875  | memory: 5942 | epsilon: 0.5519875915792745\n",
      "episode: 49  | score: -60.22787909166192  | memory: 6098 | epsilon: 0.5434429791822951\n",
      "episode: 50  | score: 19.74929996120312  | memory: 6225 | epsilon: 0.5365845536093917\n",
      "episode: 51  | score: 37.74731414860656  | memory: 6319 | epsilon: 0.5315640411536997\n",
      "episode: 52  | score: 141.7937516792502  | memory: 6475 | epsilon: 0.5233355795630413\n",
      "episode: 53  | score: -15.636566139921314  | memory: 6585 | epsilon: 0.5176101495110504\n",
      "episode: 54  | score: 20.19577145807432  | memory: 6687 | epsilon: 0.5123570994307086\n",
      "episode: 55  | score: 17.645891156428092  | memory: 6770 | epsilon: 0.5081219240356483\n",
      "episode: 56  | score: -45.45595177716666  | memory: 6916 | epsilon: 0.5007568714041313\n",
      "episode: 57  | score: -22.48746646469104  | memory: 7187 | epsilon: 0.48736793032774756\n",
      "episode: 58  | score: -56.38894925812889  | memory: 7316 | epsilon: 0.48112095132103044\n",
      "episode: 59  | score: -151.25568587375977  | memory: 7522 | epsilon: 0.47131076110131476\n",
      "episode: 60  | score: 24.417415229311928  | memory: 7812 | epsilon: 0.45783836930372745\n",
      "episode: 61  | score: 76.1195416391655  | memory: 7974 | epsilon: 0.45048077724879876\n",
      "episode: 62  | score: -4.050836834337389  | memory: 8062 | epsilon: 0.44653374148407504\n",
      "episode: 63  | score: 93.64127833453782  | memory: 8197 | epsilon: 0.4405457464825062\n",
      "episode: 64  | score: -117.94321354972811  | memory: 8378 | epsilon: 0.4326432070747788\n",
      "episode: 65  | score: 68.39789885109268  | memory: 8603 | epsilon: 0.4230169550545884\n",
      "episode: 66  | score: -4.324450610867856  | memory: 8796 | epsilon: 0.41493060776720714\n",
      "episode: 67  | score: -80.12223605022558  | memory: 9020 | epsilon: 0.40573903255557364\n",
      "episode: 68  | score: -125.44259443365462  | memory: 9178 | epsilon: 0.39937841898049015\n",
      "episode: 69  | score: 159.45189091438726  | memory: 10000 | epsilon: 0.3613707304709577\n",
      "episode: 70  | score: 26.405223567491277  | memory: 10000 | epsilon: 0.3505848887648805\n",
      "episode: 71  | score: 199.93299321304508  | memory: 10000 | epsilon: 0.3172207393390314\n",
      "episode: 72  | score: 89.45661753552642  | memory: 10000 | epsilon: 0.3095428851084682\n",
      "episode: 73  | score: -146.2273648459653  | memory: 10000 | epsilon: 0.305697490560222\n",
      "episode: 74  | score: 87.75683092281682  | memory: 10000 | epsilon: 0.2982985393565247\n",
      "episode: 75  | score: -157.97880131861666  | memory: 10000 | epsilon: 0.29256703645809856\n",
      "episode: 76  | score: -212.9356799169152  | memory: 10000 | epsilon: 0.2864295951631413\n",
      "episode: 77  | score: -224.94470974332899  | memory: 10000 | epsilon: 0.2799445701266096\n",
      "episode: 78  | score: -95.42805173801634  | memory: 10000 | epsilon: 0.27492290548662884\n",
      "episode: 79  | score: -137.3102991392759  | memory: 10000 | epsilon: 0.26985635114325546\n",
      "episode: 80  | score: -45.00221929359415  | memory: 10000 | epsilon: 0.2662109672957924\n",
      "episode: 81  | score: -93.67139926477745  | memory: 10000 | epsilon: 0.26135723409832956\n",
      "episode: 82  | score: -121.15695091706783  | memory: 10000 | epsilon: 0.2584720668422177\n",
      "episode: 83  | score: -106.31701082896694  | memory: 10000 | epsilon: 0.2517373568750095\n",
      "episode: 84  | score: -50.29606627416803  | memory: 10000 | epsilon: 0.24712280129709416\n",
      "episode: 85  | score: -217.33577599866237  | memory: 10000 | epsilon: 0.24295701489720728\n",
      "episode: 86  | score: -324.2052645469231  | memory: 10000 | epsilon: 0.2402749708112941\n",
      "episode: 87  | score: -217.7240267435268  | memory: 10000 | epsilon: 0.23319674213781794\n",
      "episode: 88  | score: -166.44918643700942  | memory: 10000 | epsilon: 0.2287161040282598\n",
      "episode: 89  | score: 138.48235455276114  | memory: 10000 | epsilon: 0.20694985421133028\n",
      "episode: 90  | score: -180.2233889624369  | memory: 10000 | epsilon: 0.2008131770916578\n",
      "episode: 91  | score: 65.21925258112245  | memory: 10000 | epsilon: 0.1817023680925316\n",
      "episode: 92  | score: 161.6565229653634  | memory: 10000 | epsilon: 0.16441027948760706\n",
      "episode: 93  | score: 20.555602419536598  | memory: 10000 | epsilon: 0.1487638289195423\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LunarSafe-v0')\n",
    "n_states = env.observation_space.shape[0] - 2\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "# Get memory from agent for training set\n",
    "agent = sa.agents.DQNAgent(env, n_states, n_actions, tb=True)\n",
    "scores, bounds = agent.train_agent(episodes=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.utils.plot_visuals(agent, scores, bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-torture",
   "metadata": {},
   "source": [
    "## Test set\n",
    "\n",
    "How to update agent's network to include safety bounds in calculations?\n",
    "\n",
    "Build a seperate safety critic network. \n",
    "    + Include bounds as parameter for reward calculations.?\n",
    "    + Include bounds as parameter for agent action?\n",
    "    \n",
    "    s (list): The state. Attributes:\n",
    "                  s[0] is the horizontal coordinate\n",
    "                  s[1] is the vertical coordinate\n",
    "                  s[2] is the horizontal speed\n",
    "                  s[3] is the vertical speed\n",
    "                  s[4] is the angle\n",
    "                  s[5] is the angular speed\n",
    "                  s[6] 1 if first leg has contact, else 0\n",
    "                  s[7] 1 if second leg has contact, else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-familiar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "periodic-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-blanket",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "american-network",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# state = v_speed, l_bound, bound\n",
    "\n",
    "def safety_critic(state_size, action_size, learning_rate=0.0001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=state_size, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(32, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(action_size, activation='linear', kernel_initializer='he_uniform'))\n",
    "    #model.summary()\n",
    "    model.compile(loss='mse', optimizer=Adam(lr=learning_rate))\n",
    "    return model\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-framework",
   "language": "python",
   "name": "test-framework"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
